{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM57hKj/iXLvbktjEVgCid/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minonza/NLP/blob/main/NLP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKu5qDgtxRMO"
      },
      "source": [
        "***Word Embedding_1, count vectorizaation BOW, n-gram***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4QgbuP7xsDc"
      },
      "source": [
        "*machine learning models do not understand any string or word it understands number. we willuse technique which will convert the text into number.\n",
        "\n",
        "this number is called vector*\n",
        "\n",
        "\n",
        "high level word embedding\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TuH-6aWyeIn"
      },
      "source": [
        "**BOW** model is used in NLP to represent the given text/sentence/document without giving any importance to grammer or occurance order of the words.\n",
        "\n",
        "--> it keeps count of frequency of the words in the text document.\n",
        "\n",
        "ex: my name is mini sharma. my father is a manager.\n",
        "I:2 is:2, father:1\n",
        "\n",
        "\n",
        "\n",
        "drawback: gives more importance to stopwords.  to resove this Tf-idf was introduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_-8Gfpp03pb"
      },
      "source": [
        "**n-gram** keeps context of text intact. N-gram is sequence of words from a given text document. unlike bow method.. which only cares about frequency and doesnt care about grammer.\n",
        "\n",
        "n=1 unigram\n",
        "\n",
        "n=2 bigram\n",
        "\n",
        "n=3 trigram and so n.\n",
        "\n",
        "example: I went for a cup of coffee but i ended up having lunch with her.\n",
        "\n",
        "unigram: i,went,to,have,a,cup,of,coffee......\n",
        "\n",
        "bigram, i went, to have, a cup ,.....\n",
        "\n",
        "trigram, i went to, a cup of, coffee and ended,....."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9KmizUF23OL"
      },
      "source": [
        "bow method is nothing but n-gram n=1\n",
        "\n",
        "**skip grams:** words not necessary be in the same order some words can be skipped.\n",
        "example: i dont understand what is the problem here.\n",
        "\n",
        "1 skip 2 grams: i understand, dont what , understand is, what the , is problem, the here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXNQhxvqwsMU",
        "outputId": "2ee4c173-8d7b-48b4-d9f3-52510257a8b0"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "string=[\"This is an example of bag of words!\"] #single document (\",\" seperates each document)\n",
        "vect1=CountVectorizer() #converts text into tokens\n",
        "vect1.fit_transform(string)\n",
        "print(\"bag of words\",vect1.get_feature_names())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bag of words ['an', 'bag', 'example', 'is', 'of', 'this', 'words']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BkNuSsz52XT",
        "outputId": "8b0676d0-4267-452b-bf2f-fb91423d94c6"
      },
      "source": [
        "vect1.vocabulary_"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'an': 0, 'bag': 1, 'example': 2, 'is': 3, 'of': 4, 'this': 5, 'words': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ff34Zf56KbB",
        "outputId": "17139e14-0136-427b-e6ee-b5b77ac79ce0"
      },
      "source": [
        "#fit and transform to check if the word is present or not\n",
        "c_vect=CountVectorizer()\n",
        "c_vect.fit(string)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47JeIid_648O",
        "outputId": "0ce50a9a-4902-465a-865d-3ee3533f21c4"
      },
      "source": [
        "string2=['Lets understand is of word is']\n",
        "c_new_vect=c_vect.transform(string2)\n",
        "print(\"text present at\",c_new_vect.toarray())\n",
        "#compare with indexes\n",
        "print(\"original indexes\",vect1.get_feature_names()) #occurance of is and of"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text present at [[0 0 0 2 1 0 0]]\n",
            "original indexes ['an', 'bag', 'example', 'is', 'of', 'this', 'words']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLDaAxXk7gMd",
        "outputId": "6f795179-403b-41ad-ae8a-f5ac343f5846"
      },
      "source": [
        "##bag of words using stopwords (you can avoid writing extra steps to remove stopwords)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopwords=stopwords.words('english')\n",
        "string=[\"This is an example of bag of words\"]\n",
        "vect1=CountVectorizer(stop_words=stopwords)\n",
        "print(vect1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 1), preprocessor=None,\n",
            "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
            "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
            "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
            "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
            "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
            "                            'itself', ...],\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5QRbF1-4Cw",
        "outputId": "2b2a91e4-2120-4a1e-88f9-abc9d309e852"
      },
      "source": [
        "vect1.fit_transform(string)\n",
        "print(\"bag of words:\",vect1.get_feature_names())\n",
        "print(\"vocab           :vect1.vocabulary_\")#printing only important words except stop words"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bag of words: ['bag', 'example', 'words']\n",
            "vocab           :vect1.vocabulary_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8czn791SBUWj"
      },
      "source": [
        "def text_matrix(message, countvect):\n",
        "  terms_doc=countvect.fit_transform(message)\n",
        "  return pd.DataFrame(terms_doc.toarray(),columns=countvect.get_feature_names())\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "F8y6iFHwCD9T",
        "outputId": "9dd3ba1a-a47f-45e9-e0dd-924673fdeda5"
      },
      "source": [
        "message=['A message is a discrete unit of communication intended by the source for consumption by some recipient or group of recipients.']\n",
        "c_vect=CountVectorizer()\n",
        "print(\"below matyrix is bag of words approach\")\n",
        "text_matrix(message,c_vect)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "below matyrix is bag of words approach\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>by</th>\n",
              "      <th>communication</th>\n",
              "      <th>consumption</th>\n",
              "      <th>discrete</th>\n",
              "      <th>for</th>\n",
              "      <th>group</th>\n",
              "      <th>intended</th>\n",
              "      <th>is</th>\n",
              "      <th>message</th>\n",
              "      <th>of</th>\n",
              "      <th>or</th>\n",
              "      <th>recipient</th>\n",
              "      <th>recipients</th>\n",
              "      <th>some</th>\n",
              "      <th>source</th>\n",
              "      <th>the</th>\n",
              "      <th>unit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   by  communication  consumption  discrete  ...  some  source  the  unit\n",
              "0   2              1            1         1  ...     1       1    1     1\n",
              "\n",
              "[1 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4RvEtptCgNF",
        "outputId": "807b24fd-7b9b-4cee-bb02-5f2b67904841"
      },
      "source": [
        "#n-grams\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "string=[\"This is an exmaple of gram!\"]\n",
        "vect1=CountVectorizer(ngram_range=(1,1))\n",
        "\n",
        "vect1.fit_transform(string)\n",
        "\n",
        "vect2=CountVectorizer(ngram_range=(2,2))\n",
        "\n",
        "vect2.fit_transform(string)\n",
        "\n",
        "vect3=CountVectorizer(ngram_range=(3,3))\n",
        "\n",
        "vect3.fit_transform(string)\n",
        "\n",
        "vect4=CountVectorizer(ngram_range=(4,4))\n",
        "\n",
        "vect4.fit_transform(string)\n",
        "\n",
        "print(\"1-gram:\",vect1.get_feature_names())\n",
        "print(\"2-gram:\",vect2.get_feature_names())\n",
        "print(\"3-gram:\",vect3.get_feature_names())\n",
        "print(\"4-gram:\",vect4.get_feature_names())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-gram: ['an', 'exmaple', 'gram', 'is', 'of', 'this']\n",
            "2-gram: ['an exmaple', 'exmaple of', 'is an', 'of gram', 'this is']\n",
            "3-gram: ['an exmaple of', 'exmaple of gram', 'is an exmaple', 'this is an']\n",
            "4-gram: ['an exmaple of gram', 'is an exmaple of', 'this is an exmaple']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvAjgxzERqQd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiFaon_iSEdb"
      },
      "source": [
        "***tf-idf --> Term frequency-inverse document frequency***\n",
        "reflects how import is a word to a document in a collection of corpus.\n",
        "\n",
        "**term frequency = (number of times word appears in document)/(total number of words in the document)**\n",
        "\n",
        "\n",
        "-disadvantage of term frequency is that gives higher weight to words with higher frequency.\n",
        "\n",
        "\n",
        "***Inverse document frequency*** = log[(Number of document)/(number of documents the word appears in)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "77ke9qtjGt6r",
        "outputId": "1b1eee95-8791-4d8d-d1dc-62b8963164e5"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "tfid=TfidfVectorizer(smooth_idf=False)\n",
        "doc=[\"This is an example\",\"we will see how it works\",\"IDF can be confusing\"]\n",
        "doc_vector=tfid.fit_transform(doc)\n",
        "df=pd.DataFrame(doc_vector.todense(),columns=tfid.get_feature_names())\n",
        "df"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>an</th>\n",
              "      <th>be</th>\n",
              "      <th>can</th>\n",
              "      <th>confusing</th>\n",
              "      <th>example</th>\n",
              "      <th>how</th>\n",
              "      <th>idf</th>\n",
              "      <th>is</th>\n",
              "      <th>it</th>\n",
              "      <th>see</th>\n",
              "      <th>this</th>\n",
              "      <th>we</th>\n",
              "      <th>will</th>\n",
              "      <th>works</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.408248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    an   be  can  confusing  ...  this        we      will     works\n",
              "0  0.5  0.0  0.0        0.0  ...   0.5  0.000000  0.000000  0.000000\n",
              "1  0.0  0.0  0.0        0.0  ...   0.0  0.408248  0.408248  0.408248\n",
              "2  0.0  0.5  0.5        0.5  ...   0.0  0.000000  0.000000  0.000000\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej2eD5ISWciJ"
      },
      "source": [
        "def text_matrix(message,countvect):\n",
        "  terms_doc=countvect.fit_transform(message)\n",
        "  return pd.DataFrame(terms_doc.toarray(),columns=countvect.get_feature_names())\n",
        "  "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "wG7gqav1Yrkg",
        "outputId": "df0810f7-6652-4bc8-fbfa-9b7c5f899e8a"
      },
      "source": [
        "feb_message=[\"Who is that covid covid\",\n",
        "             \"covid is nothing\",\n",
        "             \"covid cases are dropping\"]\n",
        "tf=TfidfVectorizer()\n",
        "text_matrix(feb_message,tf)\n",
        "             "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>are</th>\n",
              "      <th>cases</th>\n",
              "      <th>covid</th>\n",
              "      <th>dropping</th>\n",
              "      <th>is</th>\n",
              "      <th>nothing</th>\n",
              "      <th>that</th>\n",
              "      <th>who</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.592567</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.381519</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.501651</td>\n",
              "      <td>0.501651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.425441</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.547832</td>\n",
              "      <td>0.720333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.546454</td>\n",
              "      <td>0.546454</td>\n",
              "      <td>0.322745</td>\n",
              "      <td>0.546454</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        are     cases     covid  ...   nothing      that       who\n",
              "0  0.000000  0.000000  0.592567  ...  0.000000  0.501651  0.501651\n",
              "1  0.000000  0.000000  0.425441  ...  0.720333  0.000000  0.000000\n",
              "2  0.546454  0.546454  0.322745  ...  0.000000  0.000000  0.000000\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "FddkjCf_ZNCT",
        "outputId": "137f5cd1-e2bd-48e8-9de6-b6962e9aa143"
      },
      "source": [
        "jul_message=[\"what is that covid covid\",\n",
        "             \"covid is bad\"]\n",
        "text_matrix(jul_message,tf)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bad</th>\n",
              "      <th>covid</th>\n",
              "      <th>is</th>\n",
              "      <th>that</th>\n",
              "      <th>what</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.668501</td>\n",
              "      <td>0.334251</td>\n",
              "      <td>0.469778</td>\n",
              "      <td>0.469778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.704909</td>\n",
              "      <td>0.501549</td>\n",
              "      <td>0.501549</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        bad     covid        is      that      what\n",
              "0  0.000000  0.668501  0.334251  0.469778  0.469778\n",
              "1  0.704909  0.501549  0.501549  0.000000  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9_gKqUkZtaz"
      },
      "source": [
        "**Countvectorizer,TF-IDF,n-grams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqd41VzDZdFY"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "arr=['car was cleaned by jack','jack was cleaned by car.']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBnJLXaPaRj7",
        "outputId": "15494c8f-ae9a-482b-ceac-d0184e4f58fd"
      },
      "source": [
        "vectorizer=CountVectorizer(ngram_range=(2,2))\n",
        "X=vectorizer.fit_transform(arr)\n",
        "print(\"feature names \\n\",vectorizer.get_feature_names())\n",
        "print(\"Array \\n\",X.toarray())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature names \n",
            " ['by car', 'by jack', 'car was', 'cleaned by', 'jack was', 'was cleaned']\n",
            "Array \n",
            " [[0 1 1 1 0 1]\n",
            " [1 0 0 1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CahpWnToa7-K",
        "outputId": "14553409-81ee-40b5-878a-32a68d6776c8"
      },
      "source": [
        "vectorizer=TfidfVectorizer(ngram_range=(2,2))\n",
        "X=vectorizer.fit_transform(arr)\n",
        "print(X.toarray())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.57615236 0.57615236 0.40993715 0.         0.40993715]\n",
            " [0.57615236 0.         0.         0.40993715 0.57615236 0.40993715]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-Sch8iborcN"
      },
      "source": [
        "**Word2Vec**\n",
        "\n",
        "in one hot encoding  1. have a good day 2. have a great day\n",
        "\n",
        "\n",
        "they both have same encoding thats why we use word2vec.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRhf5Q5dbpiJ"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gck03ibop_We"
      },
      "source": [
        "paragraph=\"\"\"Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus(for example, by coughing into a flexed elbow). Most people infected with the COVID-19 virus will experience mild to moderate respiratory illness and recover without requiring special treatment.  Older people, and those with underlying medical problems like cardiovascular disease, diabetes, chronic respiratory disease, and cancer are more likely to develop serious illness.\n",
        "\n",
        "The best way to prevent and slow down transmission is to be well informed about the COVID-19 virus, the disease it causes and how it spreads. Protect yourself and others from infection by washing your hands or using an alcohol based rub frequently and not touching your face. \n",
        "\n",
        "The COVID-19 virus spreads primarily through droplets of saliva or discharge from the nose when an infected person coughs or sneezes, so it’s important that you also practice respiratory etiquette (for example, by coughing into a flexed elbow).\"\"\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsxoYA_BqzjM"
      },
      "source": [
        "\n",
        "paragraph = paragraph.translate(str.maketrans(\" \",\" \",string.punctuation))\n",
        "text=re.sub(r'\\[[0-9]*\\]',' ',paragraph)\n",
        "text=re.sub(r'\\s+',' ',text)\n",
        "text=text.lower()\n",
        "text=re.sub(r'\\d',' ',text)\n",
        "text=re.sub(r'\\s+',' ',text)\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7Qffcu1rwIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b890dfdb-cb66-467f-bff6-dde6c0f43345"
      },
      "source": [
        "#preparing the dataset\n",
        "nltk.download('punkt')\n",
        "sentences = nltk.sent_tokenize(text)\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMWlO3L9XCkE",
        "outputId": "5c8eda14-551a-4170-a0b8-35ab5e0265b3"
      },
      "source": [
        "sent_word=[nltk.word_tokenize(sentence) for sentence in sentences]\n",
        "print(sent_word)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['coronavirus', 'disease', 'covid', 'is', 'an', 'infectious', 'disease', 'caused', 'by', 'a', 'newly', 'discovered', 'coronavirusfor', 'example', 'by', 'coughing', 'into', 'a', 'flexed', 'elbow', 'most', 'people', 'infected', 'with', 'the', 'covid', 'virus', 'will', 'experience', 'mild', 'to', 'moderate', 'respiratory', 'illness', 'and', 'recover', 'without', 'requiring', 'special', 'treatment', 'older', 'people', 'and', 'those', 'with', 'underlying', 'medical', 'problems', 'like', 'cardiovascular', 'disease', 'diabetes', 'chronic', 'respiratory', 'disease', 'and', 'cancer', 'are', 'more', 'likely', 'to', 'develop', 'serious', 'illness', 'the', 'best', 'way', 'to', 'prevent', 'and', 'slow', 'down', 'transmission', 'is', 'to', 'be', 'well', 'informed', 'about', 'the', 'covid', 'virus', 'the', 'disease', 'it', 'causes', 'and', 'how', 'it', 'spreads', 'protect', 'yourself', 'and', 'others', 'from', 'infection', 'by', 'washing', 'your', 'hands', 'or', 'using', 'an', 'alcohol', 'based', 'rub', 'frequently', 'and', 'not', 'touching', 'your', 'face', 'the', 'covid', 'virus', 'spreads', 'primarily', 'through', 'droplets', 'of', 'saliva', 'or', 'discharge', 'from', 'the', 'nose', 'when', 'an', 'infected', 'person', 'coughs', 'or', 'sneezes', 'so', 'it', '’', 's', 'important', 'that', 'you', 'also', 'practice', 'respiratory', 'etiquette', 'for', 'example', 'by', 'coughing', 'into', 'a', 'flexed', 'elbow']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maBtKFGnXZ7d"
      },
      "source": [
        ""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qEz3HcwZX4I1",
        "outputId": "130a90b6-6acd-4543-90dd-eef447d999f5"
      },
      "source": [
        "punc=string.punctuation\n",
        "punc"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2u9KSNgYLPM"
      },
      "source": [
        "for i in range(len(sent_word)):\n",
        "  sent_word[i]=[word for word in sent_word[i]\n",
        "                if word not in stopwords.words('english') if word not in punc]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ4CJcNSYj_E"
      },
      "source": [
        "model=Word2Vec(sent_word,min_count=1)\n",
        "words=model.wv.vocab"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjMVMKJNYokn",
        "outputId": "eeddef06-4972-4610-e926-37a2a9cf07dc"
      },
      "source": [
        "vector=model.wv['covid']\n",
        "print(vector)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2.4644772e-03 -2.4026323e-03 -1.6915271e-03 -3.4454272e-03\n",
            " -1.9637994e-03  1.4502263e-03 -4.0057451e-03 -5.0268770e-04\n",
            "  1.5123765e-03 -4.5204065e-03  1.0447941e-03  4.9018380e-03\n",
            "  3.1340558e-03 -1.8535989e-03  4.2031375e-03  1.4384763e-03\n",
            " -3.6380009e-03 -6.0185877e-04  3.1975952e-03  2.6860682e-03\n",
            "  2.7918611e-03  3.8005046e-03 -2.0421389e-03 -3.9887475e-03\n",
            "  5.4314482e-04  3.1554056e-04  2.6066063e-03 -8.8046677e-04\n",
            " -3.7421010e-04 -2.5100629e-03  4.5233178e-03 -4.4533494e-03\n",
            "  4.7770548e-03  4.1449200e-03 -2.3442409e-03  4.2953459e-03\n",
            " -4.9711671e-04 -2.9974990e-03 -4.3178378e-03  1.1965767e-03\n",
            "  1.1391431e-03  2.7671794e-03  6.6914159e-04  3.4631097e-03\n",
            " -5.4776546e-04 -4.0721903e-03 -2.5708410e-03 -1.8198419e-03\n",
            " -9.4564102e-04  3.7373605e-03 -4.4691721e-03 -2.5960542e-03\n",
            "  1.9991223e-03  1.2973349e-03 -2.5526113e-03 -3.9138026e-03\n",
            "  4.2627344e-04  2.7380602e-03 -3.7244288e-03  8.0644801e-05\n",
            " -4.0676100e-03 -2.8395932e-03 -1.9313694e-03  1.1229976e-03\n",
            " -4.2664669e-03  2.9517887e-03 -1.7507847e-03 -1.9881274e-03\n",
            " -1.9159169e-03 -2.3603959e-03  4.3848502e-03  4.7449046e-03\n",
            " -4.1161608e-03  2.6435233e-03  3.1741979e-03 -2.9277871e-03\n",
            " -4.5734276e-03 -1.5411159e-03  1.0056907e-03 -8.0569682e-04\n",
            " -1.7609848e-03 -3.4784211e-03 -3.7947751e-03 -4.5077968e-03\n",
            "  1.8017938e-03 -2.8116053e-03  4.5106569e-03 -2.5653054e-03\n",
            "  2.3545814e-03 -6.5006560e-04 -8.1649842e-04 -4.3942598e-03\n",
            "  2.9217137e-03 -4.0794956e-03  1.4957007e-03 -2.0425348e-03\n",
            " -3.3684878e-03  2.5172119e-03  1.0967747e-03 -1.9699188e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Li2svdjY27i"
      },
      "source": [
        "similar=model.wv.most_similar('coronavirus',topn=5)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIn0iyzUZFIw",
        "outputId": "85fa13db-af03-4f1a-9611-19d7a5dc6293"
      },
      "source": [
        "similar"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('recover', 0.18466618657112122),\n",
              " ('likely', 0.1837800145149231),\n",
              " ('caused', 0.16574087738990784),\n",
              " ('virus', 0.16325588524341583),\n",
              " ('rub', 0.1601230353116989)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJfUTcH1Zpcg",
        "outputId": "4eb22d87-7346-4d25-9e35-2ffdd4ab0d7f"
      },
      "source": [
        "model.wv.similarity(w1='coronavirus',w2='virus')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.16325589"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "vJQkcpeWZ6VF",
        "outputId": "d9ce2221-52cf-49c1-f244-ec9ce25828f6"
      },
      "source": [
        "#filter non simiarity\n",
        "model.wv.doesnt_match([\"infection\",\"spread\"])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'infection'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Y0L3v2b_adNa",
        "outputId": "f25b76eb-84cb-43af-d20a-0be0aed863c3"
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "vocab=['recover','likely','virus','rub']\n",
        "def tsne_plot(model):\n",
        "  labels=[]\n",
        "  wordvecs=[]\n",
        "  for word in vocab:\n",
        "    wordvecs.append(model[word])\n",
        "    labels.append(word)\n",
        "  tsne_model=TSNE(perplexity=3,n_components=2,init='pca',random_state=42)\n",
        "  cordinates=tsne_model.fit_transform(wordvecs)\n",
        "  x=[]\n",
        "  y=[]\n",
        "  for value in cordinates:\n",
        "    x.append(value[0])\n",
        "    y.append(value[1])\n",
        "  plt.figure(figsize=(10,6))\n",
        "  for i in range(len(x)):\n",
        "    plt.scatter(x[i],y[i])\n",
        "    plt.annotate(labels[i],\n",
        "                 xy=(x[i],y[i]),\n",
        "                 xytext=(2, 2),\n",
        "                 textcoords='offset points', ha ='right')\n",
        "    \n",
        "tsne_plot(model)\n",
        "plt.show()        "
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk3XExsZfMIF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}