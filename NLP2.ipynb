{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJFnOQUV07am/HOLF0zVRY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minonza/NLP/blob/main/NLP2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKu5qDgtxRMO"
      },
      "source": [
        "***Word Embedding_1, count vectorizaation BOW, n-gram***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4QgbuP7xsDc"
      },
      "source": [
        "*machine learning models do not understand any string or word it understands number. we willuse technique which will convert the text into number.\n",
        "\n",
        "this number is called vector*\n",
        "\n",
        "\n",
        "high level word embedding\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TuH-6aWyeIn"
      },
      "source": [
        "**BOW** model is used in NLP to represent the given text/sentence/document without giving any importance to grammer or occurance order of the words.\n",
        "\n",
        "--> it keeps count of frequency of the words in the text document.\n",
        "\n",
        "ex: my name is mini sharma. my father is a manager.\n",
        "I:2 is:2, father:1\n",
        "\n",
        "\n",
        "\n",
        "drawback: gives more importance to stopwords.  to resove this Tf-idf was introduced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_-8Gfpp03pb"
      },
      "source": [
        "**n-gram** keeps context of text intact. N-gram is sequence of words from a given text document. unlike bow method.. which only cares about frequency and doesnt care about grammer.\n",
        "\n",
        "n=1 unigram\n",
        "\n",
        "n=2 bigram\n",
        "\n",
        "n=3 trigram and so n.\n",
        "\n",
        "example: I went for a cup of coffee but i ended up having lunch with her.\n",
        "\n",
        "unigram: i,went,to,have,a,cup,of,coffee......\n",
        "\n",
        "bigram, i went, to have, a cup ,.....\n",
        "\n",
        "trigram, i went to, a cup of, coffee and ended,....."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9KmizUF23OL"
      },
      "source": [
        "bow method is nothing but n-gram n=1\n",
        "\n",
        "**skip grams:** words not necessary be in the same order some words can be skipped.\n",
        "example: i dont understand what is the problem here.\n",
        "\n",
        "1 skip 2 grams: i understand, dont what , understand is, what the , is problem, the here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXNQhxvqwsMU",
        "outputId": "87adf6a4-00f6-4215-cb22-fea4a30c67cd"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "import pandas as pd\n",
        "string=[\"This is an example of bag of words!\"] #single document (\",\" seperates each document)\n",
        "vect1=CountVectorizer() #converts text into tokens\n",
        "vect1.fit_transform(string)\n",
        "print(\"bag of words\",vect1.get_feature_names())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bag of words ['an', 'bag', 'example', 'is', 'of', 'this', 'words']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BkNuSsz52XT",
        "outputId": "aa19791f-9b21-4996-89c3-ce157e89d290"
      },
      "source": [
        "vect1.vocabulary_"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'an': 0, 'bag': 1, 'example': 2, 'is': 3, 'of': 4, 'this': 5, 'words': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ff34Zf56KbB",
        "outputId": "ce6d1fd7-41be-4c10-ff96-fdcfede895a8"
      },
      "source": [
        "#fit and transform to check if the word is present or not\n",
        "c_vect=CountVectorizer()\n",
        "c_vect.fit(string)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47JeIid_648O",
        "outputId": "8312b981-aaa8-41e7-adc2-ad98b54d7e5b"
      },
      "source": [
        "string2=['Lets understand is of word is']\n",
        "c_new_vect=c_vect.transform(string2)\n",
        "print(\"text present at\",c_new_vect.toarray())\n",
        "#compare with indexes\n",
        "print(\"original indexes\",vect1.get_feature_names()) #occurance of is and of"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "text present at [[0 0 0 2 1 0 0]]\n",
            "original indexes ['an', 'bag', 'example', 'is', 'of', 'this', 'words']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLDaAxXk7gMd",
        "outputId": "288d9c24-70a9-4f26-f624-d43a80be8685"
      },
      "source": [
        "##bag of words using stopwords (you can avoid writing extra steps to remove stopwords)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopwords=stopwords.words('english')\n",
        "string=[\"This is an example of bag of words\"]\n",
        "vect1=CountVectorizer(stop_words=stopwords)\n",
        "print(vect1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 1), preprocessor=None,\n",
            "                stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
            "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
            "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
            "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
            "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
            "                            'itself', ...],\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5QRbF1-4Cw",
        "outputId": "bd348fa3-d9bd-4d10-84d9-416a6d6b606e"
      },
      "source": [
        "vect1.fit_transform(string)\n",
        "print(\"bag of words:\",vect1.get_feature_names())\n",
        "print(\"vocab           :vect1.vocabulary_\")#printing only important words except stop words"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bag of words: ['bag', 'example', 'words']\n",
            "vocab           :vect1.vocabulary_\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8czn791SBUWj"
      },
      "source": [
        "def text_matrix(message, countvect):\n",
        "  terms_doc=countvect.fit_transform(message)\n",
        "  return pd.DataFrame(terms_doc.toarray(),columns=countvect.get_feature_names())\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "F8y6iFHwCD9T",
        "outputId": "1df55da0-cebf-43f2-8398-3500f70696e0"
      },
      "source": [
        "message=['A message is a discrete unit of communication intended by the source for consumption by some recipient or group of recipients.']\n",
        "c_vect=CountVectorizer()\n",
        "print(\"below matyrix is bag of words approach\")\n",
        "text_matrix(message,c_vect)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "below matyrix is bag of words approach\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>by</th>\n",
              "      <th>communication</th>\n",
              "      <th>consumption</th>\n",
              "      <th>discrete</th>\n",
              "      <th>for</th>\n",
              "      <th>group</th>\n",
              "      <th>intended</th>\n",
              "      <th>is</th>\n",
              "      <th>message</th>\n",
              "      <th>of</th>\n",
              "      <th>or</th>\n",
              "      <th>recipient</th>\n",
              "      <th>recipients</th>\n",
              "      <th>some</th>\n",
              "      <th>source</th>\n",
              "      <th>the</th>\n",
              "      <th>unit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   by  communication  consumption  discrete  ...  some  source  the  unit\n",
              "0   2              1            1         1  ...     1       1    1     1\n",
              "\n",
              "[1 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4RvEtptCgNF",
        "outputId": "7c26ae21-da52-4280-9868-0f85fd23b7f8"
      },
      "source": [
        "#n-grams\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "string=[\"This is an exmaple of gram!\"]\n",
        "vect1=CountVectorizer(ngram_range=(1,1))\n",
        "\n",
        "vect1.fit_transform(string)\n",
        "\n",
        "vect2=CountVectorizer(ngram_range=(2,2))\n",
        "\n",
        "vect2.fit_transform(string)\n",
        "\n",
        "vect3=CountVectorizer(ngram_range=(3,3))\n",
        "\n",
        "vect3.fit_transform(string)\n",
        "\n",
        "vect4=CountVectorizer(ngram_range=(4,4))\n",
        "\n",
        "vect4.fit_transform(string)\n",
        "\n",
        "print(\"1-gram:\",vect1.get_feature_names())\n",
        "print(\"2-gram:\",vect2.get_feature_names())\n",
        "print(\"3-gram:\",vect3.get_feature_names())\n",
        "print(\"4-gram:\",vect4.get_feature_names())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1-gram: ['an', 'exmaple', 'gram', 'is', 'of', 'this']\n",
            "2-gram: ['an exmaple', 'exmaple of', 'is an', 'of gram', 'this is']\n",
            "3-gram: ['an exmaple of', 'exmaple of gram', 'is an exmaple', 'this is an']\n",
            "4-gram: ['an exmaple of gram', 'is an exmaple of', 'this is an exmaple']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvAjgxzERqQd"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiFaon_iSEdb"
      },
      "source": [
        "***tf-idf --> Term frequency-inverse document frequency***\n",
        "reflects how import is a word to a document in a collection of corpus.\n",
        "\n",
        "**term frequency = (number of times word appears in document)/(total number of words in the document)**\n",
        "\n",
        "\n",
        "-disadvantage of term frequency is that gives higher weight to words with higher frequency.\n",
        "\n",
        "\n",
        "***Inverse document frequency*** = log[(Number of document)/(number of documents the word appears in)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "77ke9qtjGt6r",
        "outputId": "8cc84e03-1b2f-4063-d64c-e93f9b019dd3"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "tfid=TfidfVectorizer(smooth_idf=False)\n",
        "doc=[\"This is an example\",\"we will see how it works\",\"IDF can be confusing\"]\n",
        "doc_vector=tfid.fit_transform(doc)\n",
        "df=pd.DataFrame(doc_vector.todense(),columns=tfid.get_feature_names())\n",
        "df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>an</th>\n",
              "      <th>be</th>\n",
              "      <th>can</th>\n",
              "      <th>confusing</th>\n",
              "      <th>example</th>\n",
              "      <th>how</th>\n",
              "      <th>idf</th>\n",
              "      <th>is</th>\n",
              "      <th>it</th>\n",
              "      <th>see</th>\n",
              "      <th>this</th>\n",
              "      <th>we</th>\n",
              "      <th>will</th>\n",
              "      <th>works</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.408248</td>\n",
              "      <td>0.408248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    an   be  can  confusing  ...  this        we      will     works\n",
              "0  0.5  0.0  0.0        0.0  ...   0.5  0.000000  0.000000  0.000000\n",
              "1  0.0  0.0  0.0        0.0  ...   0.0  0.408248  0.408248  0.408248\n",
              "2  0.0  0.5  0.5        0.5  ...   0.0  0.000000  0.000000  0.000000\n",
              "\n",
              "[3 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ej2eD5ISWciJ"
      },
      "source": [
        "def text_matrix(message,countvect):\n",
        "  terms_doc=countvect.fit_transform(message)\n",
        "  return pd.DataFrame(terms_doc.toarray(),columns=countvect.get_feature_names())\n",
        "  "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "wG7gqav1Yrkg",
        "outputId": "10f74966-a440-4768-e242-7a47d166b51a"
      },
      "source": [
        "feb_message=[\"Who is that covid covid\",\n",
        "             \"covid is nothing\",\n",
        "             \"covid cases are dropping\"]\n",
        "tf=TfidfVectorizer()\n",
        "text_matrix(feb_message,tf)\n",
        "             "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>are</th>\n",
              "      <th>cases</th>\n",
              "      <th>covid</th>\n",
              "      <th>dropping</th>\n",
              "      <th>is</th>\n",
              "      <th>nothing</th>\n",
              "      <th>that</th>\n",
              "      <th>who</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.592567</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.381519</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.501651</td>\n",
              "      <td>0.501651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.425441</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.547832</td>\n",
              "      <td>0.720333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.546454</td>\n",
              "      <td>0.546454</td>\n",
              "      <td>0.322745</td>\n",
              "      <td>0.546454</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        are     cases     covid  ...   nothing      that       who\n",
              "0  0.000000  0.000000  0.592567  ...  0.000000  0.501651  0.501651\n",
              "1  0.000000  0.000000  0.425441  ...  0.720333  0.000000  0.000000\n",
              "2  0.546454  0.546454  0.322745  ...  0.000000  0.000000  0.000000\n",
              "\n",
              "[3 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "FddkjCf_ZNCT",
        "outputId": "d5a123e3-346b-472a-ef55-00941a4c04f4"
      },
      "source": [
        "jul_message=[\"what is that covid covid\",\n",
        "             \"covid is bad\"]\n",
        "text_matrix(jul_message,tf)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bad</th>\n",
              "      <th>covid</th>\n",
              "      <th>is</th>\n",
              "      <th>that</th>\n",
              "      <th>what</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.668501</td>\n",
              "      <td>0.334251</td>\n",
              "      <td>0.469778</td>\n",
              "      <td>0.469778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.704909</td>\n",
              "      <td>0.501549</td>\n",
              "      <td>0.501549</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        bad     covid        is      that      what\n",
              "0  0.000000  0.668501  0.334251  0.469778  0.469778\n",
              "1  0.704909  0.501549  0.501549  0.000000  0.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9_gKqUkZtaz"
      },
      "source": [
        "**Countvectorizer,TF-IDF,n-grams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqd41VzDZdFY"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "arr=['car was cleaned by jack','jack was cleaned by car.']"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBnJLXaPaRj7",
        "outputId": "24fcf858-3d5c-4615-d2e1-dfd5e489b82d"
      },
      "source": [
        "vectorizer=CountVectorizer(ngram_range=(2,2))\n",
        "X=vectorizer.fit_transform(arr)\n",
        "print(\"feature names \\n\",vectorizer.get_feature_names())\n",
        "print(\"Array \\n\",X.toarray())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature names \n",
            " ['by car', 'by jack', 'car was', 'cleaned by', 'jack was', 'was cleaned']\n",
            "Array \n",
            " [[0 1 1 1 0 1]\n",
            " [1 0 0 1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CahpWnToa7-K",
        "outputId": "2a2c34d8-28c3-4bc2-8248-cb1ee1c83c1e"
      },
      "source": [
        "vectorizer=TfidfVectorizer(ngram_range=(2,2))\n",
        "X=vectorizer.fit_transform(arr)\n",
        "print(X.toarray())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.         0.57615236 0.57615236 0.40993715 0.         0.40993715]\n",
            " [0.57615236 0.         0.         0.40993715 0.57615236 0.40993715]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-Sch8iborcN"
      },
      "source": [
        "**Word2Vec**\n",
        "\n",
        "in one hot encoding  1. have a good day 2. have a great day\n",
        "\n",
        "\n",
        "they both have same encoding thats why we use word2vec.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRhf5Q5dbpiJ"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.corpus import stopwords\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "gck03ibop_We",
        "outputId": "ee2bece9-1978-44d2-d693-edf9f7d21287"
      },
      "source": [
        "\"\"\"Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus.\n",
        "\n",
        "Most people infected with the COVID-19 virus will experience mild to moderate respiratory illness and recover without requiring special treatment.  Older people, and those with underlying medical problems like cardiovascular disease, diabetes, chronic respiratory disease, and cancer are more likely to develop serious illness.\n",
        "\n",
        "The best way to prevent and slow down transmission is to be well informed about the COVID-19 virus, the disease it causes and how it spreads. Protect yourself and others from infection by washing your hands or using an alcohol based rub frequently and not touching your face. \n",
        "\n",
        "The COVID-19 virus spreads primarily through droplets of saliva or discharge from the nose when an infected person coughs or sneezes, so it’s important that you also practice respiratory etiquette (for example, by coughing into a flexed elbow).\"\"\""
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Coronavirus disease (COVID-19) is an infectious disease caused by a newly discovered coronavirus.\\n\\nMost people infected with the COVID-19 virus will experience mild to moderate respiratory illness and recover without requiring special treatment.  Older people, and those with underlying medical problems like cardiovascular disease, diabetes, chronic respiratory disease, and cancer are more likely to develop serious illness.\\n\\nThe best way to prevent and slow down transmission is to be well informed about the COVID-19 virus, the disease it causes and how it spreads. Protect yourself and others from infection by washing your hands or using an alcohol based rub frequently and not touching your face. \\n\\nThe COVID-19 virus spreads primarily through droplets of saliva or discharge from the nose when an infected person coughs or sneezes, so it’s important that you also practice respiratory etiquette (for example, by coughing into a flexed elbow).'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "TsxoYA_BqzjM",
        "outputId": "bae91c87-0f14-4a64-e0a7-5db9f68393ad"
      },
      "source": [
        "\n",
        "paragraph = paragraph.translate(str.maketrans('','',string.punctuation))\n",
        "text=re.sub(r'\\[[0-9]*\\]','',paragraph)\n",
        "text=re.sub(r'\\s+','',text)\n",
        "text=text.lower()\n",
        "text=re.sub(r'\\d','',text)\n",
        "text=re.sub(r'\\s+','',text)\n",
        "\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-dfe74818ab02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparagraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaketrans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\[[0-9]*\\]'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\s+'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'punctuation'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7Qffcu1rwIV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}